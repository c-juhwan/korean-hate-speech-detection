{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd03e5722b678611390efb691cd042b19d6a1c84033434cef78dfdb8ed3093fccda",
   "display_name": "Python 3.8.8 64-bit ('nlp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Korean Hate Speech Detection\n",
    "\n",
    "From Kaggle competition: https://www.kaggle.com/c/korean-hate-speech-detection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 0. Import Required Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "source": [
    "## 1. Check Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<bound method NDFrame.head of                                                comments label\n0     (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...  hate\n1     ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...  none\n2     ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...  hate\n3                    1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데  none\n4     1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...  hate\n...                                                 ...   ...\n7891                                      힘내세요~ 응원합니다!!  none\n7892                             힘내세요~~삼가 고인의 명복을 빕니다..  none\n7893                              힘내세용 ^^ 항상 응원합니닷 ^^ !  none\n7894  힘내소...연기로 답해요.나도 53살 인데 이런일 저런일 다 있더라구요.인격을 믿습...  none\n7895                                 힘들면 관뒀어야지 그게 현명한거다  none\n\n[7896 rows x 2 columns]>\n<bound method NDFrame.head of                                               comments      label\n0                          송중기 시대극은 믿고본다. 첫회 신선하고 좋았다.       none\n1                                              지현우 나쁜놈  offensive\n2           알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라       hate\n3                                     설마 ㅈ 현정 작가 아니지??       hate\n4    이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...  offensive\n..                                                 ...        ...\n466                                  지현우 범죄 저지르지 않았나요?  offensive\n467                                    여자인생 망칠 일 있나 ㅋㅋ       hate\n468            근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?  offensive\n469  할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...       hate\n470  남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...       none\n\n[471 rows x 2 columns]>\n<bound method NDFrame.head of                                               comments\n0         ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ\n1                                        둘다 넘 좋다~행복하세요\n2                 근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데\n3                원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요\n4                                   장현승 얘도 참 이젠 짠하다...\n..                                                 ...\n969                     대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹\n970  성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...\n971  분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...\n972                               입에 손가릭이 10개 있으니 징그럽다\n973                              난 조보아 이뻐서 보는데 백종원 관심무\n\n[974 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('./dataset/train.hate.csv')\n",
    "df_validation = pd.read_csv('./dataset/dev.hate.csv')\n",
    "df_test = pd.read_csv('./dataset/test.hate.no_label.csv')\n",
    "\n",
    "dataframes = [df_train, df_validation, df_test]\n",
    "\n",
    "for df in dataframes:\n",
    "    print(df.head)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## 2. Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.1 Remove unwanted part from comment\n",
    "\n",
    "1. 각종 이모티콘, 특수문자 등을 제거하여 효율성 증대\n",
    "2. 반복되는 문자를 동일하게 처리해서 효율성 증대 ex. ㅋㅋㅋㅋㅋㅋㅋㅋ -> ㅋㅋ"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import re\n",
    "\n",
    "regular_expression1 = \"[^a-zA-Z0-9ㄱ-ㅎㅏ-ㅣ가-힣 ]\"\n",
    "regular_expression2 = \"ㅋ{3,}\"\n",
    "\n",
    "for df in dataframes:\n",
    "    df['comments'] = df['comments'].str.replace(regular_expression1, \"\")\n",
    "    df['comments'] = df['comments'].str.replace(regular_expression2, \"ㅋㅋ\")\n",
    "    \n",
    "    #print(df.head)\n",
    "        \n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 146,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-146-190417025c3c>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n  df['comments'] = df['comments'].str.replace(regular_expression1, \"\")\n<ipython-input-146-190417025c3c>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n  df['comments'] = df['comments'].str.replace(regular_expression2, \"ㅋㅋ\")\n"
     ]
    }
   ]
  },
  {
   "source": [
    "### 2.2 Spell check\n",
    "\n",
    "인터넷 댓글이기 때문에, 맞춤법이 정확하지 않아 토큰화가 제대로 되지 않는 경우가 있다고 판단했음.\n",
    "\n",
    "이에 따라, 맞춤법 교정을 진행\n",
    "\n",
    "단점 및 부작용: 제대로 교정되지 않을 수 있음, 인터넷 유행어나 신조어 등이 제대로 분석되지 않을 수 있음"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                               comments label\n",
      "0     현재 호텔 주인 심정 아 18 난 마른하늘에 날벼락 맞고 호텔 망하게 생겼는데 누군...  hate\n",
      "1     한국적인 미인의 대표적인 분 너무나 곱고 아름다운 모습 그 모습 뒤의 슬픔을 미처 ...  none\n",
      "2     못된 놈들 남의 고통을 즐겼던 놈들 이젠 마땅한 처벌을 받아야지 그래야 공정한 사회...  hate\n",
      "3                      12화 어설펐는데 34화 지나서부터는 갈수록 너무 재밌던데  none\n",
      "4     1 사람 얼굴 손톱으로 긁은 것은 인격 살해이고 2 동영상이 몰카냐 에 걸리 안 들...  hate\n",
      "...                                                 ...   ...\n",
      "7891                                         힘내세요 응원합니다  none\n",
      "7892                                힘내세요 삼가 고인의 명복을 빕니다  none\n",
      "7893                                   힘내세요  항상 응원합니다    none\n",
      "7894  힘내소 연기로 답해요 나도 53살인데 이런 일 저런 일 다 있더라고요 인격을 믿습니다홨팅  none\n",
      "7895                                힘들면 관뒀어야지 그게 현명한 거다  none\n",
      "\n",
      "[7896 rows x 2 columns]\n",
      "                                              comments      label\n",
      "0                          송중기 시대극은 믿고 본다 첫 회 신선하고 좋았다       none\n",
      "1                                             지현우 나쁜 놈  offensive\n",
      "2    알바쓰고많이만들면되지 돈 욕심 없으면 골목식당 왜 나온 거야 긴 댕기게 나하고 산에...       hate\n",
      "3                                       설마 ㅈ 현정 작가 아니지       hate\n",
      "4    이미자 씨 송혜교 씨 돈이 그리 많으면 탈세 말고 그 돈으로 평소에 불우이웃에게 기...  offensive\n",
      "..                                                 ...        ...\n",
      "466                                   지현우 범죄 저지르지 않았나요  offensive\n",
      "467                                   여자 인생 망칠 일 있나 ㅋㅋ       hate\n",
      "468             근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가는 이유는  offensive\n",
      "469  할미 젖 x 뱃살 x 몸매 s라인 유륜은 적당해야 됨 너무 크거나 너무 작아도 x ...       hate\n",
      "470  남자가 잘못한 거라면 반성도 없다면 나였다면  여자처럼 아주 못되게 할 것 같다 왜...       none\n",
      "\n",
      "[471 rows x 2 columns]\n",
      "                                              comments\n",
      "0        ㅋㅋ 그래도 좋아해 주는 팬들 많아서 좋겠다 ㅠㅠ 너희들은 온유가 안 만져줌 ㅠㅠ\n",
      "1                                      둘 다 너무 좋다 행복하세요\n",
      "2              근데 만 원 이하는 현금결제만 하라고 써놓은 집 우리나라에 엄청 많은데\n",
      "3             원곡 생각 하나도 안 나고 러블리즈 신곡 나온 줄 너무 예쁘게 잘 봤어요\n",
      "4                                      장현승 얘도 참 이젠 짠하다\n",
      "..                                                 ...\n",
      "969                       대박 게스트 꼭 봐야지 콘셉트가 바뀌니깐 재미 지네\n",
      "970  성형으로 다 뜯어고쳐놓고 예쁜 척 성형 전 네 얼굴 다 알고 있다 순자처럼 된장 냄...\n",
      "971  분위기는 비슷하다만 전혀 다른 전개던데 무슨ㅋㅋㄱ 우리나라 사람들은 분위기만 비슷하...\n",
      "972                               입에 손가락이 10개 있으니 징그럽다\n",
      "973                              난 조보아 이뻐서 보는데 백종원 관심문\n",
      "\n",
      "[974 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from hanspell import spell_checker\n",
    "\n",
    "for df in dataframes:\n",
    "    for i in range(0, df.shape[0]):\n",
    "        result = spell_checker.check(df['comments'][i])\n",
    "        #print('Comment_' + str(i+1) + ':          ' + df['comments'][i])\n",
    "        #print('Comment_' + str(i+1) + '_Refined:  ' + result.checked)\n",
    "        df['comments'][i] = result.checked\n",
    "    print(df)"
   ]
  },
  {
   "source": [
    "### 2.3 Tokenize\n",
    "\n",
    "데이터를 토큰화해 모델에 입력으로 사용하므로, 한국어 형태소 분석기를 통해 토큰화\n",
    "\n",
    "조사 등의 불용어를 정의하고 이를 제거"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "No matching overloads found for kr.lucypark.okt.OktInterface.tokenize(list,java.lang.Boolean,java.lang.Boolean), options are:\n\tpublic java.util.List kr.lucypark.okt.OktInterface.tokenize(java.lang.String,java.lang.Boolean,java.lang.Boolean)\n\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-d515bb00da2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print('Comment_' + str(i+1) + ':          ' + df['comments'][i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#print('Comment_' + str(i+1) + '_Refined:  ' + result.checked)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mokt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/konlpy/tag/_okt.py\u001b[0m in \u001b[0;36mmorphs\u001b[0;34m(self, phrase, norm, stem)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;34m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mphrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/konlpy/tag/_okt.py\u001b[0m in \u001b[0;36mpos\u001b[0;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \"\"\"\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         tokens = self.jki.tokenize(\n\u001b[0m\u001b[1;32m     61\u001b[0m                     \u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0mjpype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: No matching overloads found for kr.lucypark.okt.OktInterface.tokenize(list,java.lang.Boolean,java.lang.Boolean), options are:\n\tpublic java.util.List kr.lucypark.okt.OktInterface.tokenize(java.lang.String,java.lang.Boolean,java.lang.Boolean)\n\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Hannanum\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "stopwords=['뭐','으면','을','의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "for df in dataframes:\n",
    "    for i in range(0, df.shape[0]):\n",
    "        #print('<Comment_' + str(i+1) + '>' + df['comments'][i])\n",
    "        #print('Comment_' + str(i+1) + ':          ' + df['comments'][i])\n",
    "        #print('Comment_' + str(i+1) + '_Refined:  ' + result.checked)\n",
    "        tmp = okt.morphs(df['comments'][i])\n",
    "        result = []\n",
    "        for word in tmp:\n",
    "            if word not in stopwords:\n",
    "                result.append(word)\n",
    "\n",
    "        df['comments'][i] = result\n",
    "    \n",
    "    print(df)\n",
    "\n",
    "    "
   ]
  },
  {
   "source": [
    "### 2.4 Integer encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 9. Export result to csv format "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_test = df_test\n",
    "result = np.zeros((974, 1), dtype=np.int64)\n",
    "\n",
    "for i in range(0, result.shape[0]):\n",
    "    result[i] = i % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-50-781d37f451a8>:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  export_test['comments'][i] = \"comment_\" + str(i+1)\n"
     ]
    }
   ],
   "source": [
    "export_test['label'] = result\n",
    "\n",
    "for i in range(0, result.shape[0]):\n",
    "    export_test['comments'][i] = \"comment_\" + str(i+1)\n",
    "\n",
    "export_test.to_csv('./export.csv', sep=',', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}